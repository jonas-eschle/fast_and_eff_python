{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPC in Python with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "jupyter": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the CPU used and the TensorFlow binaries, what we will see (not in the Jupyter Notebook) are a bunch of messages, including the following:\n",
    "`tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA`\n",
    "\n",
    "What could they mean?\n",
    "\n",
    "AVX stands for Advanced Vector Extensions and are instruction that the CPU can perform. They are specializations on vector operations (remember? SIMD, CPU inststruction set, etc.)\n",
    "\n",
    "Why do they appear?\n",
    "\n",
    "The code that we are using was not compiled with this flag on. This means, TensorFlow assumes that the CPU does not support this instructions and instead uses non-optimized ones. The reason is that this allows the binary (=compiled code) to also be run on a CPU that does not support then. While we use only some speed.\n",
    "(yes, technically TensorFlow can be faster when compiled natively on your computer, but then it takes time and effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:24:31.541409Z",
     "start_time": "2024-08-16T12:24:30.018230Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple comparison of Numpy, an AOT compiled library, versus pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = 100000\n",
    "list1 = [np.random.uniform() for _ in range(size1)]\n",
    "list2 = [np.random.uniform() for _ in range(size1)]\n",
    "list_zeros = [0] * size1\n",
    "\n",
    "ar1 = np.array(list1)\n",
    "ar2 = np.random.uniform(size=size1)  # way more efficient!\n",
    "ar_zeros = np.zeros_like(ar1) # quite useful function the *_like -> like the object\n",
    "# we could also create the below, in general better:\n",
    "# ar_empty = np.empty(shape=size1, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.45 ms ± 96.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(size1):\n",
    "    list_zeros[i] = list1[i] + list2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.5 μs ± 961 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ar1 + ar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( _playground_ : we can also try assignements here or simliar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast and slow\n",
    "\n",
    "Before we go deeper into the topic, we can draw two conclusions:\n",
    "- slow Python is not \"slow\": it is still blazingly fast on an absolute scale, e.g if you need to loop over a few hundred points, it's still nothing. But it can add up!\n",
    "- Numpy is a factor of 300 faster for this case (and: better reabable!)\n",
    "\n",
    "=> there is _no reason_ to ever add (numerical) arrays with a for loop in Python (except for numba jit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, TensorFlow is basically Numpy. Let's check that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.17546514, 8.92779882, 4.33083793, 4.96530809, 6.80797735,\n",
       "       8.06737767, 3.36438422, 0.35439775, 4.55640887, 2.92539731])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1_np = np.random.uniform(size=10, low=0, high=10)\n",
    "rnd1_np  # adding a return value on the last line without assigning it prints the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd1 = tnp.random.uniform(size=(10,),\n",
    "                         low=0,\n",
    "                         high=10)\n",
    "rnd2 = tf.random.uniform(shape=(10,),  # notice the \"shape\" argument: it's more picky than Numpy\n",
    "                         minval=0,\n",
    "                         maxval=10,\n",
    "                         dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       "array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "       4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in fact a \"numpy array wrapped\" and can explicitly be converted to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rnd1.numpy()), type(np.asarray(rnd1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other operations act as we would expect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       "array([18.94494362, 18.76141472, 11.52177648, 10.18231205, 13.20450439,\n",
       "       14.4144011 , 18.12311613, 12.13679637, 14.84699734, 18.51972251])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and it converts itself (often) to Numpy when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.99080986, 2.9599687 , 1.23360305, 0.42698015, 1.79011295,\n",
       "       2.10104762, 2.85010809, 1.4617785 , 2.20158973, 2.91885637])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(rnd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([8.76141472, 1.52177648])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...expand it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 1), dtype=float64, numpy=\n",
       "array([[[8.94494362],\n",
       "        [8.76141472],\n",
       "        [1.52177648],\n",
       "        [0.18231205],\n",
       "        [3.20450439],\n",
       "        [4.4144011 ],\n",
       "        [8.12311613],\n",
       "        [2.13679637],\n",
       "        [4.84699734],\n",
       "        [8.51972251]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1[None, :, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and broadcast with the known (maybe slightly stricter) rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float64, numpy=\n",
       "array([[8.00120164e+01, 7.83703608e+01, 1.36122048e+01, 1.63077097e+00,\n",
       "        2.86641111e+01, 3.94865689e+01, 7.26608158e+01, 1.91135231e+01,\n",
       "        4.33561180e+01, 7.62084375e+01],\n",
       "       [7.83703608e+01, 7.67623879e+01, 1.33329148e+01, 1.59731144e+00,\n",
       "        2.80759919e+01, 3.86763988e+01, 7.11699892e+01, 1.87213592e+01,\n",
       "        4.24665539e+01, 7.46448222e+01],\n",
       "       [1.36122048e+01, 1.33329148e+01, 2.31580365e+00, 2.77438182e-01,\n",
       "        4.87653941e+00, 6.71773176e+00, 1.23615671e+01, 3.25172646e+00,\n",
       "        7.37604655e+00, 1.29651133e+01],\n",
       "       [1.63077097e+00, 1.59731144e+00, 2.77438182e-01, 3.32376818e-02,\n",
       "        5.84219749e-01, 8.04798492e-01, 1.48094191e+00, 3.89563717e-01,\n",
       "        8.83665998e-01, 1.55324803e+00],\n",
       "       [2.86641111e+01, 2.80759919e+01, 4.87653941e+00, 5.84219749e-01,\n",
       "        1.02688484e+01, 1.41459677e+01, 2.60305613e+01, 6.84737336e+00,\n",
       "        1.55322243e+01, 2.73014882e+01],\n",
       "       [3.94865689e+01, 3.86763988e+01, 6.71773176e+00, 8.04798492e-01,\n",
       "        1.41459677e+01, 1.94869370e+01, 3.58586927e+01, 9.43267625e+00,\n",
       "        2.13965904e+01, 3.76094724e+01],\n",
       "       [7.26608158e+01, 7.11699892e+01, 1.23615671e+01, 1.48094191e+00,\n",
       "        2.60305613e+01, 3.58586927e+01, 6.59850156e+01, 1.73574451e+01,\n",
       "        3.93727223e+01, 6.92066953e+01],\n",
       "       [1.91135231e+01, 1.87213592e+01, 3.25172646e+00, 3.89563717e-01,\n",
       "        6.84737336e+00, 9.43267625e+00, 1.73574451e+01, 4.56589874e+00,\n",
       "        1.03570463e+01, 1.82049122e+01],\n",
       "       [4.33561180e+01, 4.24665539e+01, 7.37604655e+00, 8.83665998e-01,\n",
       "        1.55322243e+01, 2.13965904e+01, 3.93727223e+01, 1.03570463e+01,\n",
       "        2.34933832e+01, 4.12950724e+01],\n",
       "       [7.62084375e+01, 7.46448222e+01, 1.29651133e+01, 1.55324803e+00,\n",
       "        2.73014882e+01, 3.76094724e+01, 6.92066953e+01, 1.82049122e+01,\n",
       "        4.12950724e+01, 7.25856717e+01]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 = rnd1[None, :] * rnd1[:, None]\n",
    "matrix1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "*We will have exercises of this type throughout the notebook*\n",
    "\n",
    "Can you do the same with jax? Start with the following arrays below.\n",
    "\n",
    "Anything that surprises you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jrnd1 = jnp.asarray(rnd1)\n",
    "jrnd2 = jnp.asarray(rnd2)\n",
    "type(ar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Scalar tensor has no `len()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torchrnd1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnd1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:349\u001b[0m, in \u001b[0;36m_EagerTensorBase.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the length of the first dimension in the Tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mndims:\n\u001b[0;32m--> 349\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar tensor has no `len()`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Scalar tensor has no `len()`"
     ]
    }
   ],
   "source": [
    "torchrnd1 = torch.tensor(rnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/jax/_src/array.py:273\u001b[0m, in \u001b[0;36mArrayImpl.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torchrnd1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjrnd1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/jax/_src/array.py:275\u001b[0m, in \u001b[0;36mArrayImpl.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 275\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen() of unsized object\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "torchrnd1 = torch.tensor(jrnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torchrnd1 = torch.tensor(np.array(rnd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'tensor([8.9449, 8.7614, 1.5218, 0.1823, 3.2045, 4.4144, 8.1231, 2.1368, 4.8470,\n        8.5197], dtype=torch.float64)' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchrnd1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/numpy_ops/np_array_ops.py:228\u001b[0m, in \u001b[0;36marray\u001b[0;34m(val, dtype, copy, ndmin)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype:\n\u001b[1;32m    227\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m np_utils\u001b[38;5;241m.\u001b[39mresult_type(dtype)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/numpy_ops/np_array_ops.py:170\u001b[0m, in \u001b[0;36m_array_internal\u001b[0;34m(val, dtype, copy, ndmin)\u001b[0m\n\u001b[1;32m    167\u001b[0m result_t \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result_t, tensor_lib\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 170\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type_unary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# We can't call `convert_to_tensor(result_t, dtype=dtype)` here because\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;66;03m# convert_to_tensor doesn't allow incompatible arguments such as (5.5, int)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;66;03m# while np.array allows them. We need to convert-then-cast.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;66;03m# supply that information so that convert_to_tensor will do best-effort\u001b[39;00m\n\u001b[1;32m    182\u001b[0m   \u001b[38;5;66;03m# conversion to that dtype first.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m   result_t \u001b[38;5;241m=\u001b[39m np_arrays\u001b[38;5;241m.\u001b[39mconvert_to_tensor(result_t, dtype_hint\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/numpy_ops/np_utils.py:550\u001b[0m, in \u001b[0;36mresult_type_unary\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m    546\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mbytes_\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# TF and numpy has different interpretations of Python types such as\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# `float`, so we let `np_utils.result_type` decide.\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/numpy_ops/np_utils.py:532\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*arrays_and_dtypes)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays_and_dtypes:\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;66;03m# If arrays_and_dtypes is an empty list, let numpy decide what the dtype is.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   arrays_and_dtypes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray([])]\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays_and_dtypes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/numpy_ops/np_dtypes.py:190\u001b[0m, in \u001b[0;36m_result_type\u001b[0;34m(*arrays_and_dtypes)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m    189\u001b[0m arrays_and_dtypes \u001b[38;5;241m=\u001b[39m [preprocess_float(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays_and_dtypes]\n\u001b[0;32m--> 190\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays_and_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(canonicalize_dtype(dtype))\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'tensor([8.9449, 8.7614, 1.5218, 0.1823, 3.2045, 4.4144, 8.1231, 2.1368, 4.8470,\n        8.5197], dtype=torch.float64)' as a data type"
     ]
    }
   ],
   "source": [
    "tnp.array(torchrnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "       4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251],      dtype=float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array(torchrnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.asarray(torchrnd1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Array API\n",
    "\n",
    "These tensors implement (partially) the array API, a specification for communicating the data of an array-like object. `__array__` is one of the (fallback) methods, but there are more.\n",
    "\n",
    "Do not call them in applications, instead, `np.asarray` will figure out the most efficient way to retrieve the underlying data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "        4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251]),\n",
       " array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "        4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251]),\n",
       " array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "        4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchrnd1.__array__(), jrnd1.__array__(), rnd1.__array__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Equivalent operations\n",
    "\n",
    "Many operations that exist in Numpy also exist in JAX & Friends, sometimes with a different name.\n",
    "\n",
    "The concept however is exactly the same: we have higher level objects such as Tensors (or arrays) and call operations on it with arguments. This is a \"strong limitation\" (theoretically) of what we can do, however, since we do math, there is only a limited set we need, and in practice this suffices for 98% of the cases.\n",
    "\n",
    "Therefore we won't dive too deep into the possibilities of TensorFlow/JAX/torch/Numpy regarding operations but it is suggested to read the API docs of [TensorFlow](https://www.tensorflow.org/versions), [JAX](https://jax.readthedocs.io/en/latest/jax.numpy.html) or [torch](https://pytorch.org/docs/stable/torch.html), many are self-explanatory. It can be surprising that there is also some support for more exotic elements such as [RaggedTensors and operations](https://www.tensorflow.org/api_docs/python/tf/ragged?) and [SparseTensors and operations](https://www.tensorflow.org/api_docs/python/tf/sparse?) in TensorFlow or a (partial) [SciPy substitut](https://jax.readthedocs.io/en/latest/jax.scipy.html).\n",
    "\n",
    "Mostly, the differences and the terminology will be introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       " array([2.99080986, 2.9599687 , 1.23360305, 0.42698015, 1.79011295,\n",
       "        2.10104762, 2.85010809, 1.4617785 , 2.20158973, 2.91885637])>,\n",
       " <tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       " array([2.99080986, 2.9599687 , 1.23360305, 0.42698015, 1.79011295,\n",
       "        2.10104762, 2.85010809, 1.4617785 , 2.20158973, 2.91885637])>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(rnd1), tnp.sqrt(rnd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       " array([453.11492741, 443.81809024,  77.08708604,   9.23519617,\n",
       "        162.32732542, 223.61583442, 411.48444641, 108.2415244 ,\n",
       "        245.5294233 , 431.57493327])>,\n",
       " <tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       " array([453.11492741, 443.81809024,  77.08708604,   9.23519617,\n",
       "        162.32732542, 223.61583442, 411.48444641, 108.2415244 ,\n",
       "        245.5294233 , 431.57493327])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(matrix1, axis=0), tnp.sum(matrix1, axis=0)  # with the axis argument to specify over which to reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTypes\n",
    "\n",
    "TensorFlow is more picky on dtypes as Numpy and does not automatically cast dtypes. That's why we can often get a dtype error. Solution: make sure you add a `x = tf.cast(x, dtype=tf.float64)` (or whatever dtype we want) to cast it into the right dtype.\n",
    "\n",
    "One noticable difference: TensorFlow and JAX use float32 as the default for all operations. Neural Networks function quite well with that (sometimes even with float16) but for (most) scientific use-cases, we want to use float64. So yes, [currently](https://github.com/tensorflow/tensorflow/issues/26033), we have to define this in (too) many places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we can't do: assignements\n",
    "\n",
    "The idea of JAX & friends evolves around building an abstract representation of the mathematical operations, sometimes referred to as graph$^{1)}$ inside a JITted functien. This has one profound implication, namely that we cannot make an _assignement_ to a Tensor, because it is a node in a graph. The logic just does not work (exception: `tf.Variable`). This does not mean that JAX & friends would not perform in-place operations _behind the scenes_ - they very well do if it is save to do so. Since JAX & friends know the whole graph with all dependencies, this can be figured out. See aloso in the [JAX docs about assignements](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#array-updates-x-at-idx-set-y)\n",
    "\n",
    "Even in eager mode, without jit compilation, assignements could work (as for Numpy arrays), they are forbidden for consistency (one of the great plus points of TensorFlow).\n",
    "\n",
    "_1) if you're familiar with TensorFlow 1, this statement would suprise you as pretty obvious; but in TensorFlow 2, JAX & friends, this is luckily more hidden.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd1_np[5] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rnd1[5] = 42\n",
    "except TypeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed comparison\n",
    "\n",
    "Let's do the same calculation as with Numpy. The result should be comparable: both are AOT compiled libraries specialized on numerical, vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnd1_big = tf.random.uniform(shape=(size1,),  # notice the \"shape\" argument: it's more picky than Numpy\n",
    "                         minval=0,\n",
    "                         maxval=10,\n",
    "                         dtype=tf.float64)\n",
    "rnd2_big = tf.random.uniform(shape=(size1,),\n",
    "                         minval=0,\n",
    "                         maxval=10,\n",
    "                         dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jrnd1_big = jnp.asarray(rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 μs ± 3.84 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rnd1_big + rnd2_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.9 μs ± 197 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit  # using numpy, same as before\n",
    "ar1 + ar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the same as Numpy. Let's compare with smaller arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd1_np = np.asarray(rnd1)\n",
    "rnd2_np = np.asarray(rnd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.94494362, 8.76141472, 1.52177648, 0.18231205, 3.20450439,\n",
       "       4.4144011 , 8.12311613, 2.13679637, 4.84699734, 8.51972251])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd1_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 ns ± 6.85 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rnd1_np + rnd2_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 μs ± 311 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rnd1 + rnd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow is slow?\n",
    "\n",
    "We see now a significant difference in the runtime! This is because TensorFlow has a larger overhead than Numpy. As seen before, this is not/barely noticable for larger arrays, however for very small calculations, this is visible.\n",
    "\n",
    "There is more overhead because TensorFlow tries to be \"smarter\" about many things than Numpy and does not simply directly execute the computation.\n",
    "\n",
    "The cost is a slowdown on very small operations but a better scaling and improved performance with larger arrays and more complicated calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative speeds may differ, depending on the hardware used.\n",
    "# size_big = 10  # numpy faster\n",
    "size_big = 20000  # sameish\n",
    "# size_big = 100000  # TF faster\n",
    "# size_big = 1000000  # TF faster\n",
    "# size_big = 10000000  # TF faster\n",
    "# size_big = 100000000  # TF faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519 μs ± 21.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tf.random.uniform(shape=(size_big,), dtype=tf.float64) + tf.random.uniform(shape=(size_big,), dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 μs ± 14 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.random.uniform(size=(size_big,)) + np.random.uniform(size=(size_big,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing kernels\n",
    "\n",
    "In general, TensorFlow is preciser in what input arguments are required compared to Numpy and JAX and does less automatic dtype casting and asks more explicit for shapes. For example, integers don't work in the logarithm. However, this error message illustrates very well the kernel dispatch system of TensorFlow, so lets do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Log}}; Op<name=Log; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Log] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(error)\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py:5681\u001b[0m, in \u001b[0;36mlog\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   5679\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   5680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 5681\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   5683\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/fastpython311/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Log}}; Op<name=Log; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Log] name: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.math.log(5)\n",
    "except tf.errors.NotFoundError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# torch is a bit... unfriendly sometimes\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: log(): argument 'input' (position 1) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "torch.log(5)  # torch is a bit... unfriendly sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "What we see here: it searches the registered kernels and does not find any that supports this operation. We find different classifications:\n",
    "- GPU: normal GPU kernel\n",
    "- CPU: normal CPU kernel\n",
    "- XLA: [Accelerated Linear Algebra](https://www.tensorflow.org/xla) is a high-level compiler that can fuse operations, which would result in single calls to a fused kernel. JAX JIT is built around XLA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## just-in-time compilation\n",
    "\n",
    "Let's see the JIT in action. Therefore, we use the example from the slides and start modifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_log(x, y):\n",
    "    print('running Python')\n",
    "    tf.print(\"running compiled code\")\n",
    "    x_sq = tnp.log(x)\n",
    "    y_sq = tnp.log(y)\n",
    "    return x_sq + y_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As seen before, we can use it like Python. To make sure that we know when the actual Python is executed, we inserted a print and a `tf.print` or a `jax.debug.print`, the latter is a TensorFlow/JAX operation and therefore expected to be called everytime we compute something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running compiled code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=2.995732273553991>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log(4., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running compiled code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=7.688913336864796>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log(42., 52.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As we see, both the Python and TensorFlow operation execute. Now we can do the same with a decorator. Note that so far we entered pure Python numbers, not Tensors. Since we ran in eager mode, this did not matter so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_log_tf(x, y):\n",
    "    print('running Python')\n",
    "    tf.print(\"running TensorFlow\")\n",
    "    x_sq = tf.math.log(x)\n",
    "    y_sq = tf.math.log(y)\n",
    "    return x_sq + y_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6931472>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log_tf(1., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.442418>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log_tf(11., 21.)  # again with different numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As we see, Python is still run: this happens because 11. is not equal to 1., TensorFlow does not convert those to Tensors. Lets use it in the right way, with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6931472>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log_tf(tf.constant(1.), tf.constant(2.))  # first compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.488938>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_log_tf(tf.constant(11.), tf.constant(22.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now only the TensorFlow operations get executed! Everything else became static. We can illustrate this more extremely here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function(autograph=False)\n",
    "def add_rnd(x):\n",
    "    print('running Python')\n",
    "    tf.print(\"running TensorFlow\")\n",
    "    rnd_np = np.random.uniform()\n",
    "    rnd_tf = tf.random.uniform(shape=())\n",
    "    return x * rnd_np, x * rnd_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.5509533>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5707332>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The first time, the numpy code was executed as well, no difference so far. However, running it a second time, only the TensorFlow parts can change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.5509533>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6005988>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.1019067>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6360176>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We see now clearly: TensorFlow executes the function but _only cares about the TensorFlow operations_ , everything else is regarded as static. This can be a large pitfall! If we would execute this function _without_ the decorator, we would get a different result, since Numpy is also sampling a new random variable every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using XLA\n",
    "\n",
    "So far, the `tf.function` created a computational graph that allowed inputs to have various shapes without recompilation. Instead of this representation, another representation, `XLA` (accerelated Linear Algebra) is also available. It's a more strict subset of what the graph representation allows (i.e. not dynamic shapes, no `tf.print`!) but also more performant. Technically, it lowers to LLVM IR and performs optimizations at this level.\n",
    "\n",
    "To enable it in TF, we can use the switch `jit_compile=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function(autograph=False, jit_compile=True)\n",
    "def add_rnd(x):\n",
    "    print('running Python')\n",
    "    # tf.print(\"running TensorFlow\")  # not available in XLA!\n",
    "    rnd_np = np.random.uniform()\n",
    "    rnd_tf = tf.random.uniform(shape=())\n",
    "    return x * rnd_np, x * rnd_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 23:30:34.088335: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:61] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. random_uniform/RandomUniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.452369>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1837895>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## JAX JIT\n",
    "\n",
    "JAX is built around `XLA` and lowers everything to this representation. In comparison to TF, it's more specific when to specialize on an argument.\n",
    "\n",
    "The most important one is to specify the static arguments (i.e. that are used to create a new specialization of the function), `static_argnums` and `static_argnames` to specify the position or name of the argument, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def squaref(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=['subtract'])\n",
    "def square_or_subtract(x, subtract):\n",
    "    if subtract:\n",
    "        return x - 2\n",
    "    else:\n",
    "        return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(16., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squaref(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_or_subtract(4., True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(16., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_or_subtract(4., False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To pass an argument "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Large functions\n",
    "\n",
    "That being said, we can build graphs that require thousands of lines of Python code to stick them together correctly. Function calls in function calls etc are all possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes\n",
    "\n",
    "Tensors have a shape, similar to Numpy arrays. But Tensors have two kind of shapes, a static and a dynamic shape. The static shape is what can be inferred _before_ executing the computation while the dynamic shape is only inferred during the execution of the code. The latter typically arises with random variables and masking or cuts.\n",
    "\n",
    "We can access the static shape with `Tensor.shape`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If the shape is known inside a graph, this will be the same. If the shape is unknown, the unknown axis will be None.\n",
    "\n",
    "Note that unknown shapes are not supported in `XLA` (and therefore not at all in JAX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def func_shape_tf(x):\n",
    "    print(f\"static shape: {x.shape}\")  # static shape\n",
    "    tf.print('dynamic shape ',tf.shape(x))  # dynamic shape\n",
    "    x = x[x>3.5]\n",
    "    print(f\"static shape cuts applied: {x.shape}\")  # static shape\n",
    "    tf.print('dynamic shape cuts applied',tf.shape(x))  # dynamic shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static shape: (10,)\n",
      "static shape cuts applied: (None,)\n",
      "dynamic shape  [10]\n",
      "dynamic shape cuts applied [6]\n"
     ]
    }
   ],
   "source": [
    "func_shape_tf(rnd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can access the axes by indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float64, numpy=\n",
       "array([[8.00120164e+01, 7.83703608e+01, 1.36122048e+01, 1.63077097e+00,\n",
       "        2.86641111e+01, 3.94865689e+01, 7.26608158e+01, 1.91135231e+01,\n",
       "        4.33561180e+01, 7.62084375e+01],\n",
       "       [7.83703608e+01, 7.67623879e+01, 1.33329148e+01, 1.59731144e+00,\n",
       "        2.80759919e+01, 3.86763988e+01, 7.11699892e+01, 1.87213592e+01,\n",
       "        4.24665539e+01, 7.46448222e+01],\n",
       "       [1.36122048e+01, 1.33329148e+01, 2.31580365e+00, 2.77438182e-01,\n",
       "        4.87653941e+00, 6.71773176e+00, 1.23615671e+01, 3.25172646e+00,\n",
       "        7.37604655e+00, 1.29651133e+01],\n",
       "       [1.63077097e+00, 1.59731144e+00, 2.77438182e-01, 3.32376818e-02,\n",
       "        5.84219749e-01, 8.04798492e-01, 1.48094191e+00, 3.89563717e-01,\n",
       "        8.83665998e-01, 1.55324803e+00],\n",
       "       [2.86641111e+01, 2.80759919e+01, 4.87653941e+00, 5.84219749e-01,\n",
       "        1.02688484e+01, 1.41459677e+01, 2.60305613e+01, 6.84737336e+00,\n",
       "        1.55322243e+01, 2.73014882e+01],\n",
       "       [3.94865689e+01, 3.86763988e+01, 6.71773176e+00, 8.04798492e-01,\n",
       "        1.41459677e+01, 1.94869370e+01, 3.58586927e+01, 9.43267625e+00,\n",
       "        2.13965904e+01, 3.76094724e+01],\n",
       "       [7.26608158e+01, 7.11699892e+01, 1.23615671e+01, 1.48094191e+00,\n",
       "        2.60305613e+01, 3.58586927e+01, 6.59850156e+01, 1.73574451e+01,\n",
       "        3.93727223e+01, 6.92066953e+01],\n",
       "       [1.91135231e+01, 1.87213592e+01, 3.25172646e+00, 3.89563717e-01,\n",
       "        6.84737336e+00, 9.43267625e+00, 1.73574451e+01, 4.56589874e+00,\n",
       "        1.03570463e+01, 1.82049122e+01],\n",
       "       [4.33561180e+01, 4.24665539e+01, 7.37604655e+00, 8.83665998e-01,\n",
       "        1.55322243e+01, 2.13965904e+01, 3.93727223e+01, 1.03570463e+01,\n",
       "        2.34933832e+01, 4.12950724e+01],\n",
       "       [7.62084375e+01, 7.46448222e+01, 1.29651133e+01, 1.55324803e+00,\n",
       "        2.73014882e+01, 3.76094724e+01, 6.92066953e+01, 1.82049122e+01,\n",
       "        4.12950724e+01, 7.25856717e+01]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd3 = rnd1[None, :] * rnd1[:, None]\n",
    "rnd3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(rnd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd3.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Variables\n",
    "\n",
    "Stateful variable pose many problems for performance reasons, and make functions not idempotent! JAX therefore completely omits variables.\n",
    "\n",
    "TensorFlow offers the possibility to have statefull objects inside a compiled graph (which e.g. is not possible with Numba). The most commonly used one is the `tf.Variable`. Technically, they are automatically captured on the function compilation and belong to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var1 = tf.Variable(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(autograph=False)\n",
    "def scale_by_var(x):\n",
    "    print('running Python')\n",
    "    tf.print(\"running TensorFlow\")\n",
    "    return x * var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_by_var(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_by_var(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1.assign(42.)\n",
    "scale_by_var(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the output changed. This is of course especially useful in the context of model fitting libraries, be it likelihoods or neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rnd(x):\n",
    "    print('running Python')\n",
    "    tf.print(\"running TensorFlow\")\n",
    "    rnd_np = np.random.uniform()\n",
    "    rnd_tf = tf.random.uniform(shape=())\n",
    "    return x * rnd_np, x * rnd_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.3851656>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.8145858>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Python\n",
      "running TensorFlow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.09448713>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.79835534>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rnd(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can use Numpy fully compatible in eager mode, but not when decorated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_np_sqrt(x):\n",
    "    return np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.236068"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_np_sqrt(tf.constant(5.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_np_sqrt_tf = tf.function(try_np_sqrt, autograph=False)  # equivalent to decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot convert a symbolic tf.Tensor (x:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    try_np_sqrt_tf(tf.constant(5.))\n",
    "except NotImplementedError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, Numpy complains in the graph mode, given that it cannot handle the Symbolic Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the `tf.function` decorator means that we can't use any Python dynamicity. What fails when decorated but works nicely if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greater_python(x, y):\n",
    "    if x > y:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_python(tf.constant(1.), tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works again, and will fail with the graph decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_python_tf = tf.function(greater_python, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    greater_python_tf(tf.constant(1.), tf.constant(2.))\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message hints at something: while this does not work now - Python does not yet now the value of the Tensors so it can't decide whether it will evaluate to True or False - there is the possibility of \"autograph\": it automatically converts (a subset) of Python to TensorFlow: while loops, for loops through Tensors and conditionals. However, this is usually less effective and more errorprone than using explicitly the `tf.*` functions. Lets try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_python_tf_autograph = tf.function(greater_python, autograph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_python_tf_autograph(tf.constant(1.), tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now works neatless! But we're never sure.\n",
    "\n",
    "To do it explicitly, we can do that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__greater_python(x, y):\n",
      "    with ag__.FunctionScope('greater_python', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal retval_, do_return\n",
      "            do_return, retval_ = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = True\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = False\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.ld(x) > ag__.ld(y), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = tf.autograph.to_code(greater_python)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "In the end, this is what matters. And a comparison would be nice. Let's do that and see how Numpy and TensorFlow compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevents = 10000000\n",
    "data_tf = tf.random.uniform(shape=(nevents,), dtype=tf.float64)\n",
    "data_np = np.random.uniform(size=(nevents,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_np(x):\n",
    "    x_init = x\n",
    "    i = 42.\n",
    "    x = np.sqrt(np.abs(x_init * (i + 1.)))\n",
    "    x = np.cos(x - 0.3)\n",
    "    x = np.power(x, i + 1)\n",
    "    x = np.sinh(x + 0.4)\n",
    "    x = x ** 2\n",
    "    x = x / np.mean(x)\n",
    "    x = np.abs(x)\n",
    "    logx = np.log(x)\n",
    "    x = np.mean(logx)\n",
    "    \n",
    "    x1 = np.sqrt(np.abs(x_init * (i + 1.)))\n",
    "    x1 = np.cos(x1 - 0.3)\n",
    "    x1 = np.power(x1, i + 1)\n",
    "    x1 = np.sinh(x1 + 0.4)\n",
    "    x1 = x1 ** 2\n",
    "    x1 = x1 / np.mean(x1)\n",
    "    x1 = np.abs(x1)\n",
    "    logx = np.log(x1)\n",
    "    x1 = np.mean(logx)\n",
    "    \n",
    "    x2 = np.sqrt(np.abs(x_init * (i + 1.)))\n",
    "    x2 = np.cos(x2 - 0.3)\n",
    "    x2 = np.power(x2, i + 1)\n",
    "    x2 = np.sinh(x2 + 0.4)\n",
    "    x2 = x2 ** 2\n",
    "    x2 = x2 / np.mean(x2)\n",
    "    x2 = np.abs(x2)\n",
    "    logx = np.log(x2)\n",
    "    x2 = np.mean(logx)\n",
    "    return x + x1 + x2\n",
    "\n",
    "calc_np_numba = numba.njit(parallel=True)(calc_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_tf(x):\n",
    "    x_init = x\n",
    "    i = 42.\n",
    "    x = tf.sqrt(tf.abs(x_init * (tf.cast(i, dtype=tf.float64) + 1.)))\n",
    "    x = tf.cos(x - 0.3)\n",
    "    x = tf.pow(x, tf.cast(i + 1, tf.float64))\n",
    "    x = tf.sinh(x + 0.4)\n",
    "    x = x ** 2\n",
    "    x = x / tf.reduce_mean(x)\n",
    "    x = tf.abs(x)\n",
    "    x = tf.reduce_mean(tf.math.log(x))\n",
    "    \n",
    "    x1 = tf.sqrt(tf.abs(x_init * (tf.cast(i, dtype=tf.float64) + 1.)))\n",
    "    x1 = tf.cos(x1 - 0.3)\n",
    "    x1 = tf.pow(x1, tf.cast(i + 1, tf.float64))\n",
    "    x1 = tf.sinh(x1 + 0.4)\n",
    "    x1 = x1 ** 2\n",
    "    x1 = x1 / tf.reduce_mean(x1)\n",
    "    x1 = tf.abs(x1)\n",
    "    \n",
    "    x2 = tf.sqrt(tf.abs(x_init * (tf.cast(i, dtype=tf.float64) + 1.)))\n",
    "    x2 = tf.cos(x2 - 0.3)\n",
    "    x2 = tf.pow(x2, tf.cast(i + 1, tf.float64))\n",
    "    x2 = tf.sinh(x2 + 0.4)\n",
    "    x2 = x2 ** 2\n",
    "    x2 = x2 / tf.reduce_mean(x2)\n",
    "    x2 = tf.abs(x2)\n",
    "    \n",
    "    return x + x1 + x2\n",
    "\n",
    "calc_tf_func = tf.function(calc_tf, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1  # compile time, just for curiosity\n",
    "calc_tf_func(data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1  # compile time, just for curiosity\n",
    "calc_np_numba(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09 s ± 26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit calc_np(data_np)  # not compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53 s ± 137 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit calc_tf(data_tf)  # not compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 ms ± 71.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r7\n",
    "calc_np_numba(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 ms ± 15.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r7\n",
    "calc_tf_func(data_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now play around with this numbers. Depending on the size (we can go up to 10 mio) and parallelizability of the problem, the numbers differ..\n",
    "\n",
    "In general:\n",
    "- Numpy is faster for small numbers\n",
    "- TensorFlow is faster for larger arrays and well parallelizable computations. Due to the larger overhead in dispatching in eager mode, it is significantly slower for very small (1-10) sample sizes.\n",
    "\n",
    "=> there is no free lunch\n",
    "\n",
    "Note: this has not run on a GPU, which would automatically happen for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf2(x, n):\n",
    "    sum_init = tf.zeros_like(x)\n",
    "    for i in range(1, n + 1):\n",
    "        x = tf.sqrt(tf.abs(x * (tf.cast(i, dtype=tf.float64) + 1.)))\n",
    "        x = tf.cos(x - 0.3)\n",
    "        x = tf.pow(x, tf.cast(i + 1, tf.float64))\n",
    "        x = tf.sinh(x + 0.4)\n",
    "        x = x ** 2\n",
    "        x = x / tf.reduce_mean(x, axis=None)\n",
    "        x = tf.abs(x)\n",
    "        x = x - tf.reduce_mean(tf.math.log(x, name=\"Jonas_log\"), name=\"Jonas_mean\")  # name for ops, see later ;)\n",
    "        sum_init += x\n",
    "    return sum_init\n",
    "\n",
    "calc_tf_func2 = tf.function(calc_tf2, autograph=False)\n",
    "\n",
    "@numba.njit(parallel=True)  # njit is equal to jit(nopython=True), meaning \"compile everything or raise error\"\n",
    "def calc_numba2(x, n):\n",
    "    sum_init = np.zeros_like(x)\n",
    "    for i in range(1, n + 1):\n",
    "        x = np.sqrt(np.abs(x * (i + 1.)))\n",
    "        x = np.cos(x - 0.3)\n",
    "        x = np.power(x, i + 1)\n",
    "        x = np.sinh(x + 0.4)\n",
    "        x = x ** 2\n",
    "        x = x / np.mean(x)\n",
    "        x = np.abs(x)\n",
    "        x = x - np.mean(np.log(x))\n",
    "        sum_init += x\n",
    "    return sum_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1  #compile\n",
    "calc_numba2(rnd1_big.numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62229937, 0.53256975, 0.49222939, ..., 1.66407892, 0.64902505,\n",
       "       0.46597241])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_numba2(rnd1_big.numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.5 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1  #compile\n",
    "calc_tf_func2(rnd1_big, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float64, numpy=\n",
       "array([0.62229937, 0.53256975, 0.49222939, ..., 1.66407892, 0.64902505,\n",
       "       0.46597241])>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_tf_func2(rnd1_big, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94 ms ± 76.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_numba2(rnd1_big.numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 ms ± 136 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_tf_func2(rnd1_big, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float64, numpy=\n",
       "array([16.28470874, 17.46429155, 21.23315363, ..., 16.17488668,\n",
       "       15.97030245, 18.62912863])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_tf_func2(rnd1_big, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.28470877, 17.46429158, 21.23315366, ..., 16.1748867 ,\n",
       "       15.97030248, 18.62912866])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_numba2(rnd1_big.numpy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_numba2(rnd1_big.numpy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ms ± 906 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_tf_func2(rnd1_big, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Add JAX code to it, and run it once with and once without compilation.\n",
    "\n",
    "- How does it compare?\n",
    "- Rerun the TensorFlow code but use `jit_compile=True` and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Control flow\n",
    "\n",
    "While JAX & friends are independent of the Python control flow, it has its own functions for that, mainly:\n",
    "- while_loop(): a while loop taking a body and condition function\n",
    "- cond: if-like\n",
    "- case and switch_case (TF) or switch (JAX): if/elif statements\n",
    "- _where_ (which is vectorized inherently)\n",
    "\n",
    "JAX control flow is [documented here](https://jax.readthedocs.io/en/latest/jax.lax.html#control-flow-operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def true_fn():\n",
    "    return tnp.array(1.)\n",
    "\n",
    "def false_fn():\n",
    "    return tnp.array(0.)\n",
    "\n",
    "var1 = tnp.array(111.)\n",
    "var2 = tnp.array(42.)\n",
    "value = tf.cond(var1 > var2, true_fn=true_fn, false_fn=false_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### While loops\n",
    "\n",
    "We can create while loops in order to have some kind of repetitive task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond(x, y):\n",
    "    return x > y\n",
    "\n",
    "def body(x, y):\n",
    "    return x / 2, y + 1\n",
    "\n",
    "x, y = tf.while_loop(cond=cond,\n",
    "                     body=body,\n",
    "                     loop_vars=[100., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.125>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### map a function\n",
    "\n",
    "We can also map a function on each element. While this is not very efficient, it allows for high flexibility.\n",
    "\n",
    "A map is like a (parallel) for loop. More powerful (especially in JAX) is the vectorized function (like `np.vectorize`), for [JAX this is `jax.vmap`](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html#jax.vmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.32697651, 0.91132368, 0.77641278, ..., 0.98328917, 0.2543407 ,\n",
       "       0.9074935 ], dtype=float64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.map(jnp.sin, jrnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float64, numpy=\n",
       "array([0.32697651, 0.91132368, 0.77641278, ..., 0.98328917, 0.2543407 ,\n",
       "       0.9074935 ])>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.map_fn(tf.math.sin, rnd1_big)  # This is basically a for-loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "tf.map_fn(tf.math.sin, rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.5 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "jax.lax.map(jnp.sin, jrnd1_big)  # jax always compiles, can use batch size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.8 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "tf.vectorized_map(tnp.sin, rnd1_big)  # can greatly speedup things sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vsin = jax.vmap(jnp.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "vsin(jrnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float64, numpy=\n",
       "array([0.32697651, 0.91132368, 0.77641278, ..., 0.98328917, 0.2543407 ,\n",
       "       0.9074935 ])>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def do_map(func, tensor):\n",
    "    return tf.map_fn(func, tensor)\n",
    "\n",
    "do_map(tf.math.sin, rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100000,), dtype=float64, numpy=\n",
       "array([0.32697651, 0.91132368, 0.77641278, ..., 0.98328917, 0.2543407 ,\n",
       "       0.9074935 ])>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def do_map_vec(func, tensor):\n",
    "    return tf.vectorized_map(func, tensor)\n",
    "\n",
    "do_map_vec(tf.math.sin, rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.32697651, 0.91132368, 0.77641278, ..., 0.98328917, 0.2543407 ,\n",
       "       0.9074935 ], dtype=float64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@partial(jax.jit, static_argnames=['func'])\n",
    "def do_map_vec_jax(func, tensor):\n",
    "    vec_func = jax.vmap(func)\n",
    "    return vec_func(tensor)\n",
    "\n",
    "do_map_vec_jax(jnp.sin, jrnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793 ms ± 14.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "do_map(tnp.sin, rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557 μs ± 14.4 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "do_map_vec(tnp.sin, rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 μs ± 18.8 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "do_map_vec_jax(jnp.sin, jrnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 μs ± 15.8 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tnp.sin(rnd1_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 μs ± 26.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jnp.sin(jrnd1_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As we can see, the generic mapping is surely not optimal. However, it works \"always\". `vectorized_map` on the other hand has a huge speedup and performs nearly as well as using the native function! However, while this works nicely for this case, it's applications are limited and depend heavily on the use-case; more complicated examples can easily result in a longer runtime and a huge memory consumption. Caution is therefore advised when using this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Gradients\n",
    "\n",
    "TensorFlow (and PyTorch) allows us to calculate the automatic gradients using a gnadient tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=8.0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tnp.array(2.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x ** 3\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=12.0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = tape.gradient(y, x)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "JAX has a slightly different approach: it creates a gradient functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grad = jax.grad(lambda x: x ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(12., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(jnp.array(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Try to get higher derivatives. Have a look at [the JAX guide on derivatives](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#gradients)\n",
    "\n",
    " - can you get the second derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows to do many things with gradients and e.g. solve differential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Behind the scenes: computational graph\n",
    "\n",
    "We talked about the computational graph back and forth, but _where is it_ ?\n",
    "\n",
    "The graph (in TensorFlow) can be retained from a function that was already traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (x: TensorSpec(shape=(10,), dtype=tf.float64, name=None), n: Literal[2]) -> TensorSpec(shape=(10,), dtype=tf.float64, name=None) at 0x7CD7DB5C00D0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_func = calc_tf_func2.get_concrete_function(rnd1, 2)\n",
    "concrete_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7cd7b214ff40>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = concrete_func.graph\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'Cast/x' type=Const>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'Abs' type=Abs>,\n",
       " <tf.Operation 'Sqrt' type=Sqrt>,\n",
       " <tf.Operation 'sub/y' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'Cos' type=Cos>,\n",
       " <tf.Operation 'Cast_1/x' type=Const>,\n",
       " <tf.Operation 'Cast_1' type=Cast>,\n",
       " <tf.Operation 'Pow' type=Pow>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'Sinh' type=Sinh>,\n",
       " <tf.Operation 'pow_1/y' type=Const>,\n",
       " <tf.Operation 'pow_1' type=Pow>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'truediv' type=RealDiv>,\n",
       " <tf.Operation 'Abs_1' type=Abs>,\n",
       " <tf.Operation 'Jonas_log' type=Log>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Jonas_mean' type=Mean>,\n",
       " <tf.Operation 'sub_1' type=Sub>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'Cast_2/x' type=Const>,\n",
       " <tf.Operation 'Cast_2' type=Cast>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'mul_1' type=Mul>,\n",
       " <tf.Operation 'Abs_2' type=Abs>,\n",
       " <tf.Operation 'Sqrt_1' type=Sqrt>,\n",
       " <tf.Operation 'sub_2/y' type=Const>,\n",
       " <tf.Operation 'sub_2' type=Sub>,\n",
       " <tf.Operation 'Cos_1' type=Cos>,\n",
       " <tf.Operation 'Cast_3/x' type=Const>,\n",
       " <tf.Operation 'Cast_3' type=Cast>,\n",
       " <tf.Operation 'Pow_2' type=Pow>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'Sinh_1' type=Sinh>,\n",
       " <tf.Operation 'pow_3/y' type=Const>,\n",
       " <tf.Operation 'pow_3' type=Pow>,\n",
       " <tf.Operation 'Const_2' type=Const>,\n",
       " <tf.Operation 'Mean_1' type=Mean>,\n",
       " <tf.Operation 'truediv_1' type=RealDiv>,\n",
       " <tf.Operation 'Abs_3' type=Abs>,\n",
       " <tf.Operation 'Jonas_log_1' type=Log>,\n",
       " <tf.Operation 'Const_3' type=Const>,\n",
       " <tf.Operation 'Jonas_mean_1' type=Mean>,\n",
       " <tf.Operation 'sub_3' type=Sub>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'Jonas_log_1' type=Log>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_op = ops[-6]\n",
    "log_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Jonas_log_1:0' shape=(10,) dtype=float64>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Jonas_log_1:0' shape=(10,) dtype=float64>,\n",
       " <tf.Tensor 'Const_3:0' shape=(1,) dtype=int32>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_inputs_mean = ops[-4].inputs\n",
    "op_inputs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_op.outputs[0] is op_inputs_mean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The output of the log operation is the input to the mean operation! We can just walk along the graph here. TensorFlow Graphs are no magic, they are simple object that store their input, their output, their operation. That's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### jaxpr: JAX Expressions\n",
    "\n",
    "The graph \"equivalent\" in JAX is an expression, a function with inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper\n",
    "def examine_jaxpr(closed_jaxpr):\n",
    "  jaxpr = closed_jaxpr.jaxpr\n",
    "  print(\"invars:\", jaxpr.invars)\n",
    "  print(\"outvars:\", jaxpr.outvars)\n",
    "  print(\"constvars:\", jaxpr.constvars)\n",
    "  for eqn in jaxpr.eqns:\n",
    "    print(\"equation:\", eqn.invars, eqn.primitive, eqn.outvars, eqn.params)\n",
    "  print()\n",
    "  print(\"jaxpr:\", jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n",
      "=====\n",
      "invars: [Var(id=137265412096960):int64[]]\n",
      "outvars: [Var(id=137265412102336):int64[]]\n",
      "constvars: []\n",
      "equation: [Var(id=137265412096960):int64[], 1] add [Var(id=137265412102336):int64[]] {}\n",
      "\n",
      "jaxpr: { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:i64[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:i64[]\u001b[39m = add a 1 \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }\n"
     ]
    }
   ],
   "source": [
    "def foo(x):\n",
    "  return x + 1\n",
    "    \n",
    "print(\"foo\")\n",
    "print(\"=====\")\n",
    "examine_jaxpr(jax.make_jaxpr(foo)(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n",
      "=====\n",
      "invars: [Var(id=137265208912768):float64[5,10], Var(id=137265208912896):float64[5], Var(id=137265208914624):float64[10]]\n",
      "outvars: [Var(id=137265208912192):float64[5], Var(id=137265208914624):float64[10]]\n",
      "constvars: []\n",
      "equation: [Var(id=137265208912768):float64[5,10], Var(id=137265208914624):float64[10]] dot_general [Var(id=137265208914816):float64[5]] {'dimension_numbers': (((1,), (0,)), ((), ())), 'precision': None, 'preferred_element_type': dtype('float64')}\n",
      "equation: [Var(id=137265208914816):float64[5], Var(id=137265208912896):float64[5]] add [Var(id=137265208916096):float64[5]] {}\n",
      "equation: [1.0] broadcast_in_dim [Var(id=137265208915392):float64[5]] {'shape': (5,), 'broadcast_dimensions': ()}\n",
      "equation: [Var(id=137265208916096):float64[5], Var(id=137265208915392):float64[5]] add [Var(id=137265208912192):float64[5]] {}\n",
      "\n",
      "jaxpr: { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f64[5,10]\u001b[39m b\u001b[35m:f64[5]\u001b[39m c\u001b[35m:f64[10]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22md\u001b[35m:f64[5]\u001b[39m = dot_general[\n",
      "      dimension_numbers=(([1], [0]), ([], []))\n",
      "      preferred_element_type=float64\n",
      "    ] a c\n",
      "    e\u001b[35m:f64[5]\u001b[39m = add d b\n",
      "    f\u001b[35m:f64[5]\u001b[39m = broadcast_in_dim[broadcast_dimensions=() shape=(5,)] 1.0\n",
      "    g\u001b[35m:f64[5]\u001b[39m = add e f\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(g, c) }\n"
     ]
    }
   ],
   "source": [
    "def bar(w, b, x):\n",
    "  return jnp.dot(w, x) + b + jnp.ones(5), x\n",
    "print(\"bar\")\n",
    "print(\"=====\")\n",
    "examine_jaxpr(jax.make_jaxpr(bar)(jnp.ones((5, 10)), jnp.ones(5), jnp.ones(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
